{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"./images/DLI_Header.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the Reduction Performance with `cub`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we introduce the `cub` library and utilize it in the Jacobi iteration code to greatly improve the performance of the `jacobi` kernel. This notebook is a bit of an aside from the main focus of this course, however, the gains made from using highly optimized libraries like `cub` make it worth your being exposed to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you will:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Be able to use the `cub` library to perform optimized block level reductions, greatly reducing atomic pressure on symmetric data being used by all GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significant Atomic Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, hundreds of thousands of threads made atomic writes to `l2_norm`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "int main()\n",
    "{\n",
    "    ...\n",
    "\n",
    "    float* d_l2_norm = (float*) nvshmem_malloc(sizeof(float));\n",
    "    jacobi<<<blocks, threads_per_block>>>(f_old, f, d_l2_norm, N); // Grid launched with hundreds of thousands of threads.\n",
    "}\n",
    "\n",
    "__global__ void jacobi (const float* f_old, float* f, float* l2_norm, int N)\n",
    "{\n",
    "    ...\n",
    "\n",
    "    float l2 = (f[idx] - f_old[idx]) * (f[idx] - f_old[idx]);\n",
    "    // Here in the kernel, (practically) every thread is making atomic writes to symmetric `l2_norm`.\n",
    "    atomicAdd(l2_norm, l2);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we have hundreds of thousands of threads performing an atomic reduction to the same variable. Knowing this we might propose that there is a great deal of atomic serialization in our program, which could have a significant impact on performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile with Nsight Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Nsight Compute](https://developer.nvidia.com/nsight-compute) is a kernel profiling tool, and here we will use its command line tool `ncu` to profile the solution code from the previous notebook.\n",
    "\n",
    "`profile_one_jacobi_PE.sh` is a simple script that profiles only PE 0 (and skips the first few kernels to allow the GPU to warm up). Run the following cell to compile and run the solution application, generating profiling output for the first PE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 0 error = 0.00272958\n",
      "Iteration = 10 error = 0.00034546\n",
      "==PROF== Connected to process 28193 (/dli/task/jacobi_solution_step1)\n",
      "==PROF== Profiling \"jacobi\": 0%....50%....100%Iteration = 20 error = 0.000210903\n",
      "Iteration = 30 error = 0.000157015\n",
      "Iteration = 40 error = 0.000127122\n",
      "Iteration = 50 error = 0.00010783\n",
      "Success!\n",
      " - 19 passes\n",
      "==PROF== Disconnected from process 28193\n",
      "==PROF== Report: report.ncu-rep\n",
      "[28193] jacobi_solution_step1@127.0.0.1\n",
      "  jacobi(float const*, float*, float*, int), 2022-Sep-19 22:46:44, Context 1, Stream 7\n",
      "    Section: GPU Speed Of Light\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    DRAM Frequency                                                           cycle/usecond                         876.50\n",
      "    SM Frequency                                                             cycle/nsecond                           1.30\n",
      "    Elapsed Cycles                                                                   cycle                        3304579\n",
      "    Memory [%]                                                                           %                           1.06\n",
      "    SOL DRAM                                                                             %                           0.24\n",
      "    Duration                                                                       msecond                           2.55\n",
      "    SOL L1/TEX Cache                                                                     %                           0.93\n",
      "    SOL L2 Cache                                                                         %                           1.06\n",
      "    SM Active Cycles                                                                 cycle                     3268830.14\n",
      "    SM [%]                                                                               %                           0.48\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    Block Size                                                                                                        256\n",
      "    Grid Size                                                                                                        4096\n",
      "    Registers Per Thread                                                   register/thread                             62\n",
      "    Shared Memory Configuration Size                                                  byte                              0\n",
      "    Driver Shared Memory Per Block                                              byte/block                              0\n",
      "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
      "    Static Shared Memory Per Block                                              byte/block                              0\n",
      "    Threads                                                                         thread                        1048576\n",
      "    Waves Per SM                                                                                                    12.80\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    Block Limit SM                                                                   block                             32\n",
      "    Block Limit Registers                                                            block                              4\n",
      "    Block Limit Shared Mem                                                           block                             32\n",
      "    Block Limit Warps                                                                block                              8\n",
      "    Theoretical Active Warps per SM                                             warp/cycle                             32\n",
      "    Theoretical Occupancy                                                                %                             50\n",
      "    Achieved Occupancy                                                                   %                          39.37\n",
      "    Achieved Active Warps Per SM                                                      warp                          25.20\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!!nvcc -x cu -arch=sm_70 -rdc=true -I $NVSHMEM_HOME/include -L $NVSHMEM_HOME/lib -lnvshmem -lcuda -o jacobi_solution_step1 solutions/jacobi_step1.cpp\n",
    "!nvshmrun -np $NUM_DEVICES ./code/profile_one_jacobi_PE.sh ./jacobi_solution_step1\n",
    "!ncu -i report.ncu-rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see is that despite reasonable achieved occupancy (`Section:Occupancy` -> `Achieved Occupancy`), we are nowhere near peak theoretical memory bandwidth (`Section: GPU Speed Of Light` -> `Memory [%]`).\n",
    "\n",
    "This supports our earlier hypothesis, and is likely because we have hundreds of thousands of threads performing an atomic reduction to the same variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Reduce the Atomic Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An approach to limit the amount of atomic serialization is to [perform as much of the reduction within the block as possible](https://developer.nvidia.com/blog/faster-parallel-reductions-kepler/). In such an approach, each block would efficiently reduce each of its threads' `l2` values, and then, have only one thread for each block, perform the atomic add to the symmetrical `l2_norm` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Level Reduction with `cub`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[cub](https://docs.nvidia.com/cuda/cub/index.html) is a header library provided by NVIDIA as part of CUDA[<sup>1</sup>](#footnote1) that provides interfaces for primitive operations that are often used in kernels such as reductions and scan operations.\n",
    "\n",
    "For our current situation, let's use the [BlockReduce](https://nvlabs.github.io/cub/classcub_1_1_block_reduce.html) interface in `cub` to perform block-level reductions, and then only have thread `0` in each block perform the atomic add to the symmetric data `l2_norm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `cub::BlockReduce`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `cub` we first add the header:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "#include <cub/cub.cuh>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `BlockReduce` we then define a `BlockReduce` type with as many threads per block as we want to use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "typedef cub::BlockReduce<float, 256> BlockReduce;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BlockReduce` will be utilizing shared memory to perform its efficient block-level reduction, so next we allocate shared memory for it to use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "__shared__ typename BlockReduce::TempStorage temp_storage;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we perform the reduction, in our case a sum reduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "float reduced_value = BlockReduce(temp_storage).Sum(value_to_reduce);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Use Block Reduce in Jacobi Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, look for the FIXMEs to refactor [exercises/jacobi_step2.cpp](exercises/jacobi_step2.cpp) (which starts from the solution of the last notebook) to perform block reduction with `cub`, only performing the atomic write to the symmetric `l2_norm` with from thread `0` in each block.\n",
    "\n",
    "Check [solutions/jacobi_step2.cpp](solutions/jacobi_step2.cpp) if you need help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 0 error = 0.00272958\n",
      "Iteration = 10 error = 0.00034546\n",
      "Iteration = 20 error = 0.000210903\n",
      "Iteration = 30 error = 0.000157015\n",
      "Iteration = 40 error = 0.000127122\n",
      "Iteration = 50 error = 0.00010783\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "!nvcc -x cu -arch=sm_70 -rdc=true -I $NVSHMEM_HOME/include -L $NVSHMEM_HOME/lib -lnvshmem -lcuda -o jacobi_step2 exercises/jacobi_step2.cpp\n",
    "!nvshmrun -np $NUM_DEVICES ./jacobi_step2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile with Nsight Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, if you weren't able to complete the exercise on your own, replace `exercises/jacobi_step2.cpp` with `solutions/jacobi_step2.cpp` in the compilation cell above, and run the cell so that you have a working solution to profile below.\n",
    "\n",
    "Let's verify with Nsight Compute that we achieve a significantly higher percentage of peak throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 0 error = 0.00272958\n",
      "Iteration = 10 error = 0.00034546\n",
      "==PROF== Connected to process 28430 (/dli/task/jacobi_step2)\n",
      "==PROF== Profiling \"jacobi\": 0%....50%....100%Iteration = 20 error = 0.000210903\n",
      "Iteration = 30 error = 0.000157015\n",
      "Iteration = 40 error = 0.000127122\n",
      "Iteration = 50 error = 0.00010783\n",
      "Success!\n",
      " - 19 passes\n",
      "==PROF== Disconnected from process 28430\n",
      "==PROF== Report: report.ncu-rep\n",
      "[28430] jacobi_step2@127.0.0.1\n",
      "  jacobi(float const*, float*, float*, int), 2022-Sep-19 23:18:07, Context 1, Stream 7\n",
      "    Section: GPU Speed Of Light\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    DRAM Frequency                                                           cycle/usecond                         787.84\n",
      "    SM Frequency                                                             cycle/nsecond                           1.15\n",
      "    Elapsed Cycles                                                                   cycle                          29721\n",
      "    Memory [%]                                                                           %                          26.24\n",
      "    SOL DRAM                                                                             %                          25.88\n",
      "    Duration                                                                       usecond                          25.79\n",
      "    SOL L1/TEX Cache                                                                     %                          31.24\n",
      "    SOL L2 Cache                                                                         %                          15.20\n",
      "    SM Active Cycles                                                                 cycle                       24857.54\n",
      "    SM [%]                                                                               %                          31.73\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    Block Size                                                                                                        256\n",
      "    Grid Size                                                                                                        4096\n",
      "    Registers Per Thread                                                   register/thread                             62\n",
      "    Shared Memory Configuration Size                                                 Kbyte                           8.19\n",
      "    Driver Shared Memory Per Block                                              byte/block                              0\n",
      "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
      "    Static Shared Memory Per Block                                              byte/block                             44\n",
      "    Threads                                                                         thread                        1048576\n",
      "    Waves Per SM                                                                                                    12.80\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "    Block Limit SM                                                                   block                             32\n",
      "    Block Limit Registers                                                            block                              4\n",
      "    Block Limit Shared Mem                                                           block                            384\n",
      "    Block Limit Warps                                                                block                              8\n",
      "    Theoretical Active Warps per SM                                             warp/cycle                             32\n",
      "    Theoretical Occupancy                                                                %                             50\n",
      "    Achieved Occupancy                                                                   %                          41.44\n",
      "    Achieved Active Warps Per SM                                                      warp                          26.52\n",
      "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvshmrun -np $NUM_DEVICES ./code/profile_one_jacobi_PE.sh ./jacobi_step2\n",
    "!ncu -i report.ncu-rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that `Section: GPU Speed Of Light` -> `Memory [%]` has greatly improved and that `Section: GPU Speed Of Light` -> `Elapsed Cycles ` has greatly decreased. Interestingly we see in `Section: Launch Statistics` -> `Static Shared Memory Per Block` the shared memory we allocated for use by `BlockReduce`'s efficient reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jacobi iteration stencil is relatively simple, and we only looked at it in one dimension, but methods like this one are omnipresent in scientific computing. We can now see how straightforward it is to use NVSHMEM in problems that use a standard domain decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next and final notebook, we present you with a fully functional single GPU CUDA implementation of a 1D wave function solver, and ask you to combine all your skills thus far to refactor it using NVSHMEM.\n",
    "\n",
    "Please open the next notebook: [_Final Exercise_](14_Wave.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a much deeper dive into Jacobi Iteration using a number of multi GPU techniques, please visit [github.com/NVIDIA/multi-gpu-programming-models](https://github.com/NVIDIA/multi-gpu-programming-models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Footnotes\n",
    "\n",
    "<span id=\"footnote1\">1</span>: Starting with CUDA 11.0, cub is available as a first-class citizen of the CUDA toolkit available directly in its `include/` directory. In prior versions of CUDA, cub was bundled as part of Thrust in the CUDA toolkit. In either case, it is [available on GitHub](https://github.com/NVIDIA/cub)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
